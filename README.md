# ğŸ“ Academe

> Multi-Agent AI Assistant that adapts machine learning explanations to your level

Built with LangGraph â€¢ Powered by Google Gemini

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![LangGraph](https://img.shields.io/badge/LangGraph-0.2.45-green.svg)](https://github.com/langchain-ai/langgraph)

---

## ğŸŒŸ What Makes Academe Special?

**The Problem:** Academic papers and textbooks are often too complex for students to understand. Even when using ChatGPT, explanations can still be overly technical or frustratingly vague.

**The Insight:** The internet discovered that prompting LLMs with "explain this like I'm a 70-year-old granny" produces surprisingly better explanations. This reveals a gap: **LLMs CAN simplify complex concepts, but they need the right framing.**

**Academe's Solution:** A multi-agent system that automatically provides **adaptive, multi-level explanations**:

- ğŸˆ **Intuitive Level**: Simple analogies, everyday language, zero jargon
- ğŸ”¬ **Technical Level**: Full mathematical rigor, formulas, graduate-level detail

Both explanations are accurateâ€”just presented differently. It's like having a patient tutor who can explain the same concept multiple ways until it clicks.

---

## ğŸ—ï¸ Architecture
```
User Query
    â†“
Router Agent (keyword-based classification)
    â†“
    â”œâ”€â†’ Concept Explainer Agent â†’ Multi-level explanations
    â”‚   (Intuitive + Technical)
    â”‚
    â””â”€â†’ Code Helper Agent â†’ Educational Python code
        (Implementation + Examples + Explanations)
```

### The Three Specialized Agents

1. **Router Agent** ğŸ§­
   - Analyzes queries to determine intent
   - Routes to appropriate specialist agent
   - Uses keyword matching (v0.1) with LLM fallback option

2. **Concept Explainer Agent** ğŸ’¡ â­
   - **This is Academe's key innovation!**
   - Explains concepts at two levels simultaneously:
     - Intuitive: "Granny mode" - pure intuition, no math
     - Technical: Full rigor with mathematical notation
   - Inspired by the viral "granny mode" prompting technique

3. **Code Helper Agent** ğŸ’»
   - Generates clean, educational Python implementations
   - Includes detailed comments and docstrings
   - Provides usage examples and step-by-step explanations
   - Focuses on NumPy for mathematical operations

---

## âœ¨ Features

- ğŸ¯ **Intelligent Routing**: Automatically determines whether you want explanations or code
- ğŸ“Š **Multi-Level Explanations**: Same concept explained intuitively AND technically
- ğŸ’» **Educational Code**: Production-quality implementations with teaching focus
- ğŸ”„ **LangGraph Orchestration**: Professional multi-agent coordination
- ğŸ§ª **Fully Tested**: Comprehensive test suite with pytest
- ğŸ¨ **Clean CLI**: Beautiful command-line interface

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.11 or higher
- Conda (recommended) or venv
- Google Gemini API key ([Get one free](https://aistudio.google.com/apikey))

### Installation
```bash
# Clone the repository
git clone https://github.com/yourusername/academe.git
cd academe

# Create conda environment
conda create -n academe python=3.11
conda activate academe

# Install dependencies
pip install -r requirements.txt

# Install in editable mode
pip install -e .

# Set up environment variables
cp .env.example .env
# Add your GOOGLE_API_KEY to .env
```

### Configuration

Edit `.env`:
```bash
# LLM Configuration
LLM_PROVIDER=gemini

# API Keys
GOOGLE_API_KEY=your_key_here

# App Settings
LOG_LEVEL=INFO
```

### Usage

**Interactive Mode:**
```bash
python main.py
```

**Demo Mode:**
```bash
python main.py demo
```

**Get Help:**
```bash
python main.py help
```

---

## ğŸ’¡ Usage Examples

### Example 1: Concept Explanation

**Input:**
```
ğŸ¤” Your question: What is gradient descent?
```

**Output:**
```
## Intuitive Explanation ğŸˆ

Imagine you're blindfolded on a hilly landscape, trying to find 
the lowest valley. You feel around with your feetâ€”if you detect 
a downward slope, you take a small step in that direction...

## Technical Explanation ğŸ”¬

Gradient Descent is an iterative first-order optimization algorithm 
used to minimize a differentiable objective function J(w).

The update rule: w_{t+1} = w_t - Î±âˆ‡J(w_t)

Where Î± is the learning rate and âˆ‡J(w_t) is the gradient...

## Key Takeaway ğŸ’¡

Gradient descent finds function minima by iteratively moving in 
the direction of steepest descent.
```

### Example 2: Code Generation

**Input:**
```
ğŸ¤” Your question: Implement gradient descent in NumPy
```

**Output:**
Overview ğŸ“‹
Implementation of gradient descent optimization in NumPy for
linear regression...
Implementation ğŸ’»
pythonimport numpy as np

def gradient_descent(X, y, learning_rate=0.01, num_iterations=1000):
    """
    Performs gradient descent to optimize linear regression parameters.
    
    Args:
        X: Input features
        y: Target values
        learning_rate: Step size for updates
        num_iterations: Number of optimization steps
    """
    # [Complete working code with detailed comments]
```

## Usage Example ğŸš€
[Working example with sample data]

## How It Works ğŸ”
[Step-by-step explanation]
```

---

## ğŸ§ª Testing
```bash
# Run all tests
python -m pytest tests/ -v

# Run fast tests only (skip LLM calls)
python -m pytest tests/ -v -m "not slow"

# Run with coverage
python -m pytest tests/ --cov=academe --cov-report=term-missing

# Run specific test file
python -m pytest tests/test_router.py -v
```

---

## ğŸ“‚ Project Structure
```
academe/
â”œâ”€â”€ academe/                    # Main package
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config/                # Configuration management
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ settings.py        # Environment settings
â”‚   â”‚   â””â”€â”€ llm_config.py      # LLM factory (supports multiple providers)
â”‚   â”œâ”€â”€ agents/                # Specialized agents
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ router.py          # Routes queries to agents
â”‚   â”‚   â”œâ”€â”€ concept_explainer.py  # Multi-level explanations
â”‚   â”‚   â””â”€â”€ code_helper.py     # Code generation
â”‚   â””â”€â”€ graph/                 # LangGraph workflow
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ state.py           # State definition
â”‚       â”œâ”€â”€ nodes.py           # Node functions
â”‚       â””â”€â”€ workflow.py        # Workflow graph
â”œâ”€â”€ tests/                     # Test suite
â”‚   â”œâ”€â”€ test_router.py
â”‚   â”œâ”€â”€ test_concept_explainer.py
â”‚   â”œâ”€â”€ test_code_helper.py
â”‚   â””â”€â”€ test_workflow.py
â”œâ”€â”€ main.py                    # CLI application
â”œâ”€â”€ demo.py                    # Interactive demo
â”œâ”€â”€ requirements.txt           # Dependencies
â”œâ”€â”€ setup.py                   # Package setup
â”œâ”€â”€ pytest.ini                 # Test configuration
â”œâ”€â”€ .env                       # Environment variables (gitignored)
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ğŸ› ï¸ Technology Stack

**Core Framework:**
- [LangGraph 0.2.45](https://github.com/langchain-ai/langgraph) - Multi-agent orchestration
- [LangChain 0.3.7](https://github.com/langchain-ai/langchain) - LLM integration

**LLM Provider:**
- [Google Gemini 2.5 Flash](https://ai.google.dev/) - Fast, free-tier model

**Development:**
- Python 3.11+
- [pytest](https://pytest.org/) - Testing framework
- [Pydantic](https://docs.pydantic.dev/) - Settings validation

---

## ğŸ“ What I Learned Building This

### Technical Skills

- **Multi-Agent Architectures**: Designed and implemented a production-ready multi-agent system with specialized agents and intelligent routing
- **LangGraph Workflows**: Mastered state management, conditional edges, and node orchestration
- **Prompt Engineering**: Developed sophisticated prompts for multi-level adaptive explanations
- **Software Design**: Applied factory pattern for LLM abstraction, making the system provider-agnostic

### Key Design Decisions

1. **Why Multi-Agent vs Single LLM?**
   - Specialized agents are better at their specific tasks
   - Easier to optimize and debug individual components
   - More modular and maintainable architecture

2. **Why Keyword Routing (v0.1)?**
   - Fast and free (no additional LLM call)
   - Accurate enough for common cases
   - Can upgrade to LLM-based routing in v1.0 for better accuracy

3. **Why Multi-Level Explanations?**
   - Real problem: Academic content is often inaccessibly complex
   - Inspired by "granny mode" viral technique
   - Both levels maintain accuracy while serving different audiences

### Challenges Overcome

- **LLM Provider Selection**: Initially tried multiple Gemini models before finding the right one (gemini-2.5-flash)
- **Import Path Issues**: Learned about Python package structure and editable installs
- **State Design**: Balanced simplicity (TypedDict) with functionality

---

## ğŸ™ Acknowledgments

- **LangChain Team** for the excellent LangGraph framework
- **Google** for providing free-tier Gemini API access
- **Northeastern University** for the CS6140 Machine Learning course that inspired this project
- The viral "granny mode" technique that sparked the multi-level explanation idea

---

**Built with â¤ï¸ for learners who struggle with complex concepts**
